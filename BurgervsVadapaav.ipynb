{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Unzipping the file\n"
      ],
      "metadata": {
        "id": "BA3Wn3iqRAdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfqDVnD885v_",
        "outputId": "43c1589f-a535-4211-9979-876ff9050376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo2YjQNCP2g8"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/book/CV1/Ch2/datasets/burgervsvadapaav/dataset2.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip \"/content/drive/MyDrive/dataset.zip\""
      ],
      "metadata": {
        "id": "TfVqOqVA9RHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/dataset2/train'\n",
        "validation_data_dir = '/content/dataset2/validation'"
      ],
      "metadata": {
        "id": "aVXe8Mv1TRQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "n2JfCmYRTy4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 150,150\n",
        "#img_width, img_height = 220,220\n",
        "input_shape = (img_width, img_height, 3)"
      ],
      "metadata": {
        "id": "FhwHpmQ8UENj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "#this generates batches of augment data for training\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb9TH0szULyR",
        "outputId": "450a88ac-e2ce-47ee-fd75-a222ddf017a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9600 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for validating\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#this generates batches of augment data for validating\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n"
      ],
      "metadata": {
        "id": "HyKwnMovXi3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D,  BatchNormalization\n",
        "from tensorflow.keras.layers import  Dropout, Flatten, Dense\n"
      ],
      "metadata": {
        "id": "xsE_9I45T33P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj5Bf5EyTn-N",
        "outputId": "7404b9d8-f37d-4e92-f024-29d65864c05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 36992)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               18940416  \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,037,121\n",
            "Trainable params: 19,035,649\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "McDmiC2F-467"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi_-i98TWhai",
        "outputId": "7c3b024c-feaf-4413-b9ab-93a1af1b6323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 148, 148, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 72, 72, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 36, 36, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 34, 34, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 17, 17, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               18940416  \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,107,073\n",
            "Trainable params: 19,105,281\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN9axVEuYouE",
        "outputId": "5425d0ef-3760-430c-db65-7c5f73bb7031"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "375/375 [==============================] - 100s 259ms/step - loss: 0.7998 - accuracy: 0.5635 - val_loss: 0.7162 - val_accuracy: 0.5905\n",
            "Epoch 2/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.5934 - accuracy: 0.6897 - val_loss: 0.5406 - val_accuracy: 0.7250\n",
            "Epoch 3/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.5065 - accuracy: 0.7513 - val_loss: 0.5211 - val_accuracy: 0.7483\n",
            "Epoch 4/50\n",
            "375/375 [==============================] - 94s 252ms/step - loss: 0.4515 - accuracy: 0.7837 - val_loss: 0.6317 - val_accuracy: 0.7610\n",
            "Epoch 5/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.4240 - accuracy: 0.8033 - val_loss: 0.4417 - val_accuracy: 0.7943\n",
            "Epoch 6/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.3949 - accuracy: 0.8203 - val_loss: 0.5876 - val_accuracy: 0.7548\n",
            "Epoch 7/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.3740 - accuracy: 0.8289 - val_loss: 0.6715 - val_accuracy: 0.7772\n",
            "Epoch 8/50\n",
            "375/375 [==============================] - 94s 252ms/step - loss: 0.3560 - accuracy: 0.8411 - val_loss: 0.3979 - val_accuracy: 0.8248\n",
            "Epoch 9/50\n",
            "375/375 [==============================] - 95s 253ms/step - loss: 0.3462 - accuracy: 0.8472 - val_loss: 0.3823 - val_accuracy: 0.8320\n",
            "Epoch 10/50\n",
            "375/375 [==============================] - 95s 252ms/step - loss: 0.3370 - accuracy: 0.8510 - val_loss: 0.4035 - val_accuracy: 0.8185\n",
            "Epoch 11/50\n",
            "375/375 [==============================] - 95s 252ms/step - loss: 0.3258 - accuracy: 0.8593 - val_loss: 0.4333 - val_accuracy: 0.8263\n",
            "Epoch 12/50\n",
            "375/375 [==============================] - 95s 253ms/step - loss: 0.3060 - accuracy: 0.8663 - val_loss: 0.5232 - val_accuracy: 0.7970\n",
            "Epoch 13/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.3069 - accuracy: 0.8679 - val_loss: 0.5095 - val_accuracy: 0.8055\n",
            "Epoch 14/50\n",
            "375/375 [==============================] - 95s 253ms/step - loss: 0.2963 - accuracy: 0.8706 - val_loss: 0.4850 - val_accuracy: 0.8127\n",
            "Epoch 15/50\n",
            "375/375 [==============================] - 94s 251ms/step - loss: 0.2898 - accuracy: 0.8760 - val_loss: 0.4151 - val_accuracy: 0.8345\n",
            "Epoch 16/50\n",
            "375/375 [==============================] - 96s 255ms/step - loss: 0.2842 - accuracy: 0.8842 - val_loss: 0.3675 - val_accuracy: 0.8332\n",
            "Epoch 17/50\n",
            "375/375 [==============================] - 95s 253ms/step - loss: 0.2766 - accuracy: 0.8847 - val_loss: 0.4884 - val_accuracy: 0.8190\n",
            "Epoch 18/50\n",
            "375/375 [==============================] - 96s 256ms/step - loss: 0.2691 - accuracy: 0.8867 - val_loss: 0.4332 - val_accuracy: 0.7980\n",
            "Epoch 19/50\n",
            "375/375 [==============================] - 97s 257ms/step - loss: 0.2598 - accuracy: 0.8907 - val_loss: 0.3730 - val_accuracy: 0.8290\n",
            "Epoch 20/50\n",
            "375/375 [==============================] - 96s 257ms/step - loss: 0.2587 - accuracy: 0.8935 - val_loss: 0.7126 - val_accuracy: 0.7390\n",
            "Epoch 21/50\n",
            "375/375 [==============================] - 96s 257ms/step - loss: 0.2460 - accuracy: 0.8990 - val_loss: 0.4509 - val_accuracy: 0.7890\n",
            "Epoch 22/50\n",
            "375/375 [==============================] - 96s 257ms/step - loss: 0.2462 - accuracy: 0.9018 - val_loss: 0.4990 - val_accuracy: 0.8005\n",
            "Epoch 23/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.2414 - accuracy: 0.9043 - val_loss: 0.3541 - val_accuracy: 0.8440\n",
            "Epoch 24/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.2329 - accuracy: 0.9064 - val_loss: 0.3742 - val_accuracy: 0.8322\n",
            "Epoch 25/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.2301 - accuracy: 0.9082 - val_loss: 0.3211 - val_accuracy: 0.8650\n",
            "Epoch 26/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.2256 - accuracy: 0.9078 - val_loss: 0.3478 - val_accuracy: 0.8540\n",
            "Epoch 27/50\n",
            "375/375 [==============================] - 98s 260ms/step - loss: 0.2172 - accuracy: 0.9133 - val_loss: 0.4490 - val_accuracy: 0.8307\n",
            "Epoch 28/50\n",
            "375/375 [==============================] - 97s 260ms/step - loss: 0.2206 - accuracy: 0.9107 - val_loss: 0.3364 - val_accuracy: 0.8565\n",
            "Epoch 29/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.2223 - accuracy: 0.9108 - val_loss: 0.5220 - val_accuracy: 0.8298\n",
            "Epoch 30/50\n",
            "375/375 [==============================] - 98s 260ms/step - loss: 0.2127 - accuracy: 0.9162 - val_loss: 0.3503 - val_accuracy: 0.8522\n",
            "Epoch 31/50\n",
            "375/375 [==============================] - 98s 260ms/step - loss: 0.1993 - accuracy: 0.9218 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 32/50\n",
            "375/375 [==============================] - 99s 263ms/step - loss: 0.2040 - accuracy: 0.9197 - val_loss: 0.3275 - val_accuracy: 0.8635\n",
            "Epoch 33/50\n",
            "375/375 [==============================] - 99s 263ms/step - loss: 0.2042 - accuracy: 0.9191 - val_loss: 0.3396 - val_accuracy: 0.8540\n",
            "Epoch 34/50\n",
            "375/375 [==============================] - 97s 260ms/step - loss: 0.1907 - accuracy: 0.9259 - val_loss: 0.3522 - val_accuracy: 0.8692\n",
            "Epoch 35/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.1970 - accuracy: 0.9233 - val_loss: 0.4621 - val_accuracy: 0.8282\n",
            "Epoch 36/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.1876 - accuracy: 0.9282 - val_loss: 0.3373 - val_accuracy: 0.8593\n",
            "Epoch 37/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.1880 - accuracy: 0.9273 - val_loss: 0.3260 - val_accuracy: 0.8700\n",
            "Epoch 38/50\n",
            "375/375 [==============================] - 97s 258ms/step - loss: 0.1828 - accuracy: 0.9266 - val_loss: 0.3689 - val_accuracy: 0.8658\n",
            "Epoch 39/50\n",
            "375/375 [==============================] - 98s 261ms/step - loss: 0.1822 - accuracy: 0.9314 - val_loss: 0.4240 - val_accuracy: 0.8562\n",
            "Epoch 40/50\n",
            "375/375 [==============================] - 98s 260ms/step - loss: 0.1759 - accuracy: 0.9315 - val_loss: 0.5274 - val_accuracy: 0.8265\n",
            "Epoch 41/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.1706 - accuracy: 0.9364 - val_loss: 0.3735 - val_accuracy: 0.8742\n",
            "Epoch 42/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.1661 - accuracy: 0.9397 - val_loss: 0.3684 - val_accuracy: 0.8698\n",
            "Epoch 43/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.1752 - accuracy: 0.9341 - val_loss: 0.4686 - val_accuracy: 0.8298\n",
            "Epoch 44/50\n",
            "375/375 [==============================] - 97s 259ms/step - loss: 0.1774 - accuracy: 0.9315 - val_loss: 0.4009 - val_accuracy: 0.8438\n",
            "Epoch 45/50\n",
            "154/375 [===========>..................] - ETA: 53s - loss: 0.1627 - accuracy: 0.9359"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "Vml-PtE0sowv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01), input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yronb-oSp7s3",
        "outputId": "c4285ffa-38e9-468f-e148-73bf8f628497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               6423040   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,885,889\n",
            "Trainable params: 6,883,585\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PxQ0dsrps3Fy",
        "outputId": "6aa5cea1-9684-4e8d-ba70-c4297cf2718d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "375/375 [==============================] - 93s 210ms/step - loss: 2.0801 - accuracy: 0.5826 - val_loss: 1.6951 - val_accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.7744 - accuracy: 0.6524 - val_loss: 0.7014 - val_accuracy: 0.6827\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6778 - accuracy: 0.6932 - val_loss: 0.7754 - val_accuracy: 0.5850\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.6389 - accuracy: 0.7107 - val_loss: 0.6759 - val_accuracy: 0.6737\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6319 - accuracy: 0.7254 - val_loss: 0.6366 - val_accuracy: 0.7045\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6156 - accuracy: 0.7422 - val_loss: 0.6269 - val_accuracy: 0.7293\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6094 - accuracy: 0.7498 - val_loss: 0.5946 - val_accuracy: 0.7555\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6016 - accuracy: 0.7557 - val_loss: 0.6593 - val_accuracy: 0.7145\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5861 - accuracy: 0.7676 - val_loss: 0.7834 - val_accuracy: 0.6690\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5804 - accuracy: 0.7695 - val_loss: 0.5609 - val_accuracy: 0.7887\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5691 - accuracy: 0.7753 - val_loss: 0.6675 - val_accuracy: 0.7065\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5621 - accuracy: 0.7824 - val_loss: 0.6587 - val_accuracy: 0.6977\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5571 - accuracy: 0.7846 - val_loss: 0.5661 - val_accuracy: 0.7735\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5452 - accuracy: 0.7872 - val_loss: 0.6561 - val_accuracy: 0.7275\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5428 - accuracy: 0.7897 - val_loss: 0.5805 - val_accuracy: 0.7650\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5279 - accuracy: 0.7943 - val_loss: 0.5128 - val_accuracy: 0.7950\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5251 - accuracy: 0.7954 - val_loss: 0.5664 - val_accuracy: 0.7628\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5137 - accuracy: 0.8012 - val_loss: 0.6332 - val_accuracy: 0.7190\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5106 - accuracy: 0.8044 - val_loss: 0.5235 - val_accuracy: 0.7820\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5055 - accuracy: 0.8041 - val_loss: 0.6045 - val_accuracy: 0.7295\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5027 - accuracy: 0.8039 - val_loss: 0.5196 - val_accuracy: 0.7897\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5037 - accuracy: 0.7987 - val_loss: 1.9428 - val_accuracy: 0.5285\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5001 - accuracy: 0.7967 - val_loss: 0.5261 - val_accuracy: 0.7818\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4999 - accuracy: 0.8063 - val_loss: 0.6113 - val_accuracy: 0.7237\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5113 - accuracy: 0.7970 - val_loss: 0.5769 - val_accuracy: 0.7538\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5054 - accuracy: 0.8015 - val_loss: 0.5584 - val_accuracy: 0.7365\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.4884 - accuracy: 0.8081 - val_loss: 0.5615 - val_accuracy: 0.7510\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4892 - accuracy: 0.8120 - val_loss: 0.4626 - val_accuracy: 0.8235\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4899 - accuracy: 0.8136 - val_loss: 0.5432 - val_accuracy: 0.7940\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4890 - accuracy: 0.8092 - val_loss: 0.5221 - val_accuracy: 0.7915\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4868 - accuracy: 0.8102 - val_loss: 0.4869 - val_accuracy: 0.8278\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4886 - accuracy: 0.8124 - val_loss: 0.5554 - val_accuracy: 0.7735\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4945 - accuracy: 0.8093 - val_loss: 0.5509 - val_accuracy: 0.7542\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4875 - accuracy: 0.8134 - val_loss: 0.4453 - val_accuracy: 0.8328\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.4791 - accuracy: 0.8188 - val_loss: 0.5443 - val_accuracy: 0.7755\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4855 - accuracy: 0.8135 - val_loss: 0.4632 - val_accuracy: 0.8125\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4850 - accuracy: 0.8142 - val_loss: 0.4990 - val_accuracy: 0.7935\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4780 - accuracy: 0.8193 - val_loss: 0.4629 - val_accuracy: 0.8317\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4820 - accuracy: 0.8155 - val_loss: 0.7010 - val_accuracy: 0.6800\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4757 - accuracy: 0.8188 - val_loss: 0.5472 - val_accuracy: 0.7548\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4776 - accuracy: 0.8156 - val_loss: 0.4843 - val_accuracy: 0.8043\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4807 - accuracy: 0.8127 - val_loss: 0.5211 - val_accuracy: 0.7837\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4772 - accuracy: 0.8187 - val_loss: 0.4837 - val_accuracy: 0.8230\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4787 - accuracy: 0.8168 - val_loss: 0.5511 - val_accuracy: 0.7788\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4773 - accuracy: 0.8197 - val_loss: 0.5269 - val_accuracy: 0.7707\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4762 - accuracy: 0.8177 - val_loss: 0.5447 - val_accuracy: 0.7510\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4806 - accuracy: 0.8142 - val_loss: 0.5445 - val_accuracy: 0.7778\n",
            "Epoch 48/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4760 - accuracy: 0.8210 - val_loss: 0.4985 - val_accuracy: 0.8070\n",
            "Epoch 49/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4725 - accuracy: 0.8216 - val_loss: 0.5689 - val_accuracy: 0.7465\n",
            "Epoch 50/60\n",
            "375/375 [==============================] - 80s 214ms/step - loss: 0.4799 - accuracy: 0.8168 - val_loss: 0.5249 - val_accuracy: 0.7943\n",
            "Epoch 51/60\n",
            "375/375 [==============================] - 80s 212ms/step - loss: 0.4772 - accuracy: 0.8239 - val_loss: 0.5100 - val_accuracy: 0.8070\n",
            "Epoch 52/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.4813 - accuracy: 0.8165 - val_loss: 0.6704 - val_accuracy: 0.7070\n",
            "Epoch 53/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4813 - accuracy: 0.8143 - val_loss: 0.5096 - val_accuracy: 0.8123\n",
            "Epoch 54/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.4753 - accuracy: 0.8181 - val_loss: 0.5756 - val_accuracy: 0.7558\n",
            "Epoch 55/60\n",
            "287/375 [=====================>........] - ETA: 16s - loss: 0.4773 - accuracy: 0.8209"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0483c5e53483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01), input_shape=input_shape))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(256, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Flatten())\n",
        "\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Dropout(0.5))\n",
        "\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model2.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSxbMV3n5aLT",
        "outputId": "46140df8-1e82-4d3c-8d69-017ac2228dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 148, 148, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 15, 15, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               6423040   \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,885,889\n",
            "Trainable params: 6,883,585\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=60,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SYJVmBBj5fA5",
        "outputId": "0ef42e86-66d0-422b-a4f4-2f29381168c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "375/375 [==============================] - 79s 205ms/step - loss: 2.8284 - accuracy: 0.5822 - val_loss: 1.9945 - val_accuracy: 0.5000\n",
            "Epoch 2/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 1.1640 - accuracy: 0.6740 - val_loss: 0.8644 - val_accuracy: 0.6970\n",
            "Epoch 3/60\n",
            "375/375 [==============================] - 81s 216ms/step - loss: 0.7701 - accuracy: 0.7117 - val_loss: 0.7346 - val_accuracy: 0.6670\n",
            "Epoch 4/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6806 - accuracy: 0.7324 - val_loss: 0.8790 - val_accuracy: 0.6043\n",
            "Epoch 5/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.6542 - accuracy: 0.7390 - val_loss: 0.7816 - val_accuracy: 0.6715\n",
            "Epoch 6/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6428 - accuracy: 0.7602 - val_loss: 0.6508 - val_accuracy: 0.7560\n",
            "Epoch 7/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.6475 - accuracy: 0.7587 - val_loss: 0.8053 - val_accuracy: 0.5978\n",
            "Epoch 8/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6284 - accuracy: 0.7776 - val_loss: 0.6611 - val_accuracy: 0.7513\n",
            "Epoch 9/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6236 - accuracy: 0.7744 - val_loss: 0.9164 - val_accuracy: 0.5130\n",
            "Epoch 10/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6178 - accuracy: 0.7756 - val_loss: 1.0690 - val_accuracy: 0.5570\n",
            "Epoch 11/60\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.6109 - accuracy: 0.7772 - val_loss: 0.8455 - val_accuracy: 0.6100\n",
            "Epoch 12/60\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.6283 - accuracy: 0.7748 - val_loss: 0.6870 - val_accuracy: 0.7405\n",
            "Epoch 13/60\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.6012 - accuracy: 0.7821 - val_loss: 0.7254 - val_accuracy: 0.7063\n",
            "Epoch 14/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.6092 - accuracy: 0.7843 - val_loss: 0.7244 - val_accuracy: 0.7262\n",
            "Epoch 15/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5969 - accuracy: 0.7893 - val_loss: 0.6457 - val_accuracy: 0.7390\n",
            "Epoch 16/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5772 - accuracy: 0.7935 - val_loss: 0.6506 - val_accuracy: 0.7475\n",
            "Epoch 17/60\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5716 - accuracy: 0.7879 - val_loss: 0.6093 - val_accuracy: 0.7580\n",
            "Epoch 18/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5664 - accuracy: 0.7928 - val_loss: 0.5796 - val_accuracy: 0.7897\n",
            "Epoch 19/60\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5559 - accuracy: 0.7977 - val_loss: 0.6510 - val_accuracy: 0.7278\n",
            "Epoch 20/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5503 - accuracy: 0.7980 - val_loss: 0.5644 - val_accuracy: 0.7952\n",
            "Epoch 21/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5389 - accuracy: 0.7977 - val_loss: 0.6284 - val_accuracy: 0.7297\n",
            "Epoch 22/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5466 - accuracy: 0.8002 - val_loss: 0.5015 - val_accuracy: 0.8200\n",
            "Epoch 23/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5415 - accuracy: 0.7983 - val_loss: 0.6444 - val_accuracy: 0.6973\n",
            "Epoch 24/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5333 - accuracy: 0.7987 - val_loss: 0.5984 - val_accuracy: 0.7498\n",
            "Epoch 25/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5142 - accuracy: 0.8066 - val_loss: 0.5294 - val_accuracy: 0.7977\n",
            "Epoch 26/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5306 - accuracy: 0.8002 - val_loss: 0.6545 - val_accuracy: 0.7042\n",
            "Epoch 27/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5251 - accuracy: 0.8049 - val_loss: 0.5767 - val_accuracy: 0.7617\n",
            "Epoch 28/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5171 - accuracy: 0.8028 - val_loss: 0.5468 - val_accuracy: 0.7912\n",
            "Epoch 29/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5136 - accuracy: 0.8009 - val_loss: 0.4873 - val_accuracy: 0.8165\n",
            "Epoch 30/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5139 - accuracy: 0.8049 - val_loss: 0.5892 - val_accuracy: 0.7505\n",
            "Epoch 31/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5186 - accuracy: 0.8058 - val_loss: 0.5573 - val_accuracy: 0.7635\n",
            "Epoch 32/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5144 - accuracy: 0.8052 - val_loss: 0.5799 - val_accuracy: 0.7515\n",
            "Epoch 33/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5088 - accuracy: 0.8092 - val_loss: 0.5463 - val_accuracy: 0.7845\n",
            "Epoch 34/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5075 - accuracy: 0.8108 - val_loss: 0.5597 - val_accuracy: 0.7897\n",
            "Epoch 35/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5140 - accuracy: 0.8122 - val_loss: 0.6985 - val_accuracy: 0.6660\n",
            "Epoch 36/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5075 - accuracy: 0.8164 - val_loss: 0.4988 - val_accuracy: 0.7947\n",
            "Epoch 37/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5030 - accuracy: 0.8090 - val_loss: 0.5614 - val_accuracy: 0.7632\n",
            "Epoch 38/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.4980 - accuracy: 0.8126 - val_loss: 0.5185 - val_accuracy: 0.8012\n",
            "Epoch 39/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.4959 - accuracy: 0.8131 - val_loss: 0.5413 - val_accuracy: 0.7855\n",
            "Epoch 40/60\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5022 - accuracy: 0.8185 - val_loss: 0.5626 - val_accuracy: 0.7630\n",
            "Epoch 41/60\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.4953 - accuracy: 0.8215 - val_loss: 0.5076 - val_accuracy: 0.7915\n",
            "Epoch 42/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5006 - accuracy: 0.8149 - val_loss: 0.5598 - val_accuracy: 0.7890\n",
            "Epoch 43/60\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5064 - accuracy: 0.8138 - val_loss: 0.5906 - val_accuracy: 0.7477\n",
            "Epoch 44/60\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5126 - accuracy: 0.8140 - val_loss: 0.5580 - val_accuracy: 0.7720\n",
            "Epoch 45/60\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5038 - accuracy: 0.8097 - val_loss: 0.4780 - val_accuracy: 0.8145\n",
            "Epoch 46/60\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5043 - accuracy: 0.8140 - val_loss: 0.5365 - val_accuracy: 0.7883\n",
            "Epoch 47/60\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5113 - accuracy: 0.8190 - val_loss: 0.6258 - val_accuracy: 0.6980\n",
            "Epoch 48/60\n",
            "  8/375 [..............................] - ETA: 1:08 - loss: 0.4883 - accuracy: 0.8320"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-79f78bff6e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01), input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AK3RpiZLdOD",
        "outputId": "ac8c3879-597a-4717-a073-017d5ac05f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,793,729\n",
            "Trainable params: 2,789,889\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ5zWpsELglt",
        "outputId": "69650656-a95e-4fc7-ac9a-1803ef9b4ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 95s 213ms/step - loss: 4.1591 - accuracy: 0.5326 - val_loss: 1.6653 - val_accuracy: 0.5013\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 79s 211ms/step - loss: 1.1830 - accuracy: 0.5765 - val_loss: 1.4005 - val_accuracy: 0.5422\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.9016 - accuracy: 0.6520 - val_loss: 0.8106 - val_accuracy: 0.6817\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.7761 - accuracy: 0.6727 - val_loss: 0.9585 - val_accuracy: 0.5428\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.7307 - accuracy: 0.6917 - val_loss: 0.8420 - val_accuracy: 0.5940\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.7124 - accuracy: 0.6954 - val_loss: 0.8222 - val_accuracy: 0.5945\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6923 - accuracy: 0.7143 - val_loss: 0.6687 - val_accuracy: 0.7145\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 77s 207ms/step - loss: 0.6979 - accuracy: 0.7128 - val_loss: 0.8544 - val_accuracy: 0.5755\n",
            "Epoch 9/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6896 - accuracy: 0.7187 - val_loss: 0.7758 - val_accuracy: 0.6235\n",
            "Epoch 10/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6848 - accuracy: 0.7284 - val_loss: 0.7025 - val_accuracy: 0.7070\n",
            "Epoch 11/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6773 - accuracy: 0.7305 - val_loss: 0.6819 - val_accuracy: 0.7280\n",
            "Epoch 12/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6646 - accuracy: 0.7436 - val_loss: 0.6661 - val_accuracy: 0.7212\n",
            "Epoch 13/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6548 - accuracy: 0.7521 - val_loss: 0.7769 - val_accuracy: 0.6205\n",
            "Epoch 14/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6472 - accuracy: 0.7473 - val_loss: 0.7117 - val_accuracy: 0.7007\n",
            "Epoch 15/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6301 - accuracy: 0.7559 - val_loss: 0.7509 - val_accuracy: 0.6585\n",
            "Epoch 16/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.6232 - accuracy: 0.7623 - val_loss: 0.6120 - val_accuracy: 0.7732\n",
            "Epoch 17/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6253 - accuracy: 0.7684 - val_loss: 0.7979 - val_accuracy: 0.6225\n",
            "Epoch 18/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6184 - accuracy: 0.7648 - val_loss: 0.6763 - val_accuracy: 0.7215\n",
            "Epoch 19/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.6154 - accuracy: 0.7703 - val_loss: 0.6889 - val_accuracy: 0.6942\n",
            "Epoch 20/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.6056 - accuracy: 0.7736 - val_loss: 0.6601 - val_accuracy: 0.7312\n",
            "Epoch 21/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5996 - accuracy: 0.7728 - val_loss: 0.6737 - val_accuracy: 0.7237\n",
            "Epoch 22/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5993 - accuracy: 0.7747 - val_loss: 0.6361 - val_accuracy: 0.7462\n",
            "Epoch 23/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5946 - accuracy: 0.7761 - val_loss: 0.5922 - val_accuracy: 0.7648\n",
            "Epoch 24/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5911 - accuracy: 0.7708 - val_loss: 0.7890 - val_accuracy: 0.6423\n",
            "Epoch 25/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5855 - accuracy: 0.7785 - val_loss: 0.5998 - val_accuracy: 0.7458\n",
            "Epoch 26/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5824 - accuracy: 0.7818 - val_loss: 0.7206 - val_accuracy: 0.6285\n",
            "Epoch 27/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5852 - accuracy: 0.7797 - val_loss: 0.6194 - val_accuracy: 0.7590\n",
            "Epoch 28/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5758 - accuracy: 0.7827 - val_loss: 0.6434 - val_accuracy: 0.7197\n",
            "Epoch 29/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5669 - accuracy: 0.7815 - val_loss: 0.6425 - val_accuracy: 0.7330\n",
            "Epoch 30/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5687 - accuracy: 0.7828 - val_loss: 0.5887 - val_accuracy: 0.7725\n",
            "Epoch 31/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5719 - accuracy: 0.7814 - val_loss: 0.8028 - val_accuracy: 0.6202\n",
            "Epoch 32/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5702 - accuracy: 0.7843 - val_loss: 0.6635 - val_accuracy: 0.7092\n",
            "Epoch 33/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5621 - accuracy: 0.7801 - val_loss: 0.5832 - val_accuracy: 0.7705\n",
            "Epoch 34/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5559 - accuracy: 0.7882 - val_loss: 0.5946 - val_accuracy: 0.7710\n",
            "Epoch 35/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5541 - accuracy: 0.7877 - val_loss: 0.6063 - val_accuracy: 0.7190\n",
            "Epoch 36/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5542 - accuracy: 0.7877 - val_loss: 0.6243 - val_accuracy: 0.7222\n",
            "Epoch 37/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5496 - accuracy: 0.7877 - val_loss: 0.5757 - val_accuracy: 0.7613\n",
            "Epoch 38/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5522 - accuracy: 0.7898 - val_loss: 0.6361 - val_accuracy: 0.7335\n",
            "Epoch 39/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5499 - accuracy: 0.7885 - val_loss: 0.6489 - val_accuracy: 0.6948\n",
            "Epoch 40/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5506 - accuracy: 0.7893 - val_loss: 0.5893 - val_accuracy: 0.7602\n",
            "Epoch 41/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5481 - accuracy: 0.7859 - val_loss: 0.6253 - val_accuracy: 0.7270\n",
            "Epoch 42/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5459 - accuracy: 0.7897 - val_loss: 0.6047 - val_accuracy: 0.7555\n",
            "Epoch 43/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5438 - accuracy: 0.7945 - val_loss: 0.6419 - val_accuracy: 0.6963\n",
            "Epoch 44/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5422 - accuracy: 0.7902 - val_loss: 0.6073 - val_accuracy: 0.7582\n",
            "Epoch 45/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.5381 - accuracy: 0.7947 - val_loss: 0.5784 - val_accuracy: 0.7908\n",
            "Epoch 46/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5450 - accuracy: 0.7882 - val_loss: 0.5975 - val_accuracy: 0.7442\n",
            "Epoch 47/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5401 - accuracy: 0.7874 - val_loss: 0.5831 - val_accuracy: 0.7533\n",
            "Epoch 48/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5366 - accuracy: 0.7946 - val_loss: 0.5868 - val_accuracy: 0.7573\n",
            "Epoch 49/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5301 - accuracy: 0.7928 - val_loss: 0.5513 - val_accuracy: 0.7650\n",
            "Epoch 50/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5357 - accuracy: 0.7893 - val_loss: 0.6129 - val_accuracy: 0.7275\n",
            "Epoch 51/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5353 - accuracy: 0.7893 - val_loss: 0.6583 - val_accuracy: 0.6848\n",
            "Epoch 52/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5328 - accuracy: 0.7898 - val_loss: 0.5411 - val_accuracy: 0.7760\n",
            "Epoch 53/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5319 - accuracy: 0.7903 - val_loss: 0.6294 - val_accuracy: 0.7050\n",
            "Epoch 54/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5349 - accuracy: 0.7884 - val_loss: 0.6269 - val_accuracy: 0.7258\n",
            "Epoch 55/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5310 - accuracy: 0.7891 - val_loss: 0.5542 - val_accuracy: 0.7577\n",
            "Epoch 56/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5259 - accuracy: 0.7985 - val_loss: 0.5869 - val_accuracy: 0.7303\n",
            "Epoch 57/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5317 - accuracy: 0.7956 - val_loss: 0.6612 - val_accuracy: 0.6768\n",
            "Epoch 58/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5270 - accuracy: 0.7931 - val_loss: 0.6559 - val_accuracy: 0.6743\n",
            "Epoch 59/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5347 - accuracy: 0.7874 - val_loss: 0.5233 - val_accuracy: 0.7828\n",
            "Epoch 60/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5231 - accuracy: 0.7952 - val_loss: 0.5856 - val_accuracy: 0.7268\n",
            "Epoch 61/80\n",
            "375/375 [==============================] - 79s 211ms/step - loss: 0.5241 - accuracy: 0.7917 - val_loss: 0.5157 - val_accuracy: 0.7993\n",
            "Epoch 62/80\n",
            "375/375 [==============================] - 81s 216ms/step - loss: 0.5181 - accuracy: 0.7938 - val_loss: 0.5759 - val_accuracy: 0.7415\n",
            "Epoch 63/80\n",
            "375/375 [==============================] - 80s 212ms/step - loss: 0.5271 - accuracy: 0.7906 - val_loss: 0.5360 - val_accuracy: 0.7667\n",
            "Epoch 64/80\n",
            "375/375 [==============================] - 80s 214ms/step - loss: 0.5173 - accuracy: 0.7946 - val_loss: 0.6195 - val_accuracy: 0.6965\n",
            "Epoch 65/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.5293 - accuracy: 0.7921 - val_loss: 0.5230 - val_accuracy: 0.7857\n",
            "Epoch 66/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.5167 - accuracy: 0.7948 - val_loss: 0.5049 - val_accuracy: 0.8012\n",
            "Epoch 67/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5168 - accuracy: 0.7940 - val_loss: 0.7585 - val_accuracy: 0.6450\n",
            "Epoch 68/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5208 - accuracy: 0.7958 - val_loss: 0.5900 - val_accuracy: 0.7197\n",
            "Epoch 69/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5155 - accuracy: 0.7987 - val_loss: 0.5279 - val_accuracy: 0.7815\n",
            "Epoch 70/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5181 - accuracy: 0.7970 - val_loss: 0.4999 - val_accuracy: 0.7950\n",
            "Epoch 71/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5135 - accuracy: 0.7980 - val_loss: 0.5876 - val_accuracy: 0.7312\n",
            "Epoch 72/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5184 - accuracy: 0.7957 - val_loss: 0.5527 - val_accuracy: 0.7492\n",
            "Epoch 73/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5133 - accuracy: 0.7983 - val_loss: 0.5798 - val_accuracy: 0.7383\n",
            "Epoch 74/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5187 - accuracy: 0.7958 - val_loss: 0.5975 - val_accuracy: 0.7410\n",
            "Epoch 75/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5113 - accuracy: 0.8015 - val_loss: 0.5572 - val_accuracy: 0.7755\n",
            "Epoch 76/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5071 - accuracy: 0.8023 - val_loss: 0.5648 - val_accuracy: 0.7318\n",
            "Epoch 77/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5149 - accuracy: 0.7958 - val_loss: 0.5220 - val_accuracy: 0.7922\n",
            "Epoch 78/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5146 - accuracy: 0.7972 - val_loss: 0.6137 - val_accuracy: 0.7312\n",
            "Epoch 79/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.5219 - accuracy: 0.7878 - val_loss: 0.6863 - val_accuracy: 0.6825\n",
            "Epoch 80/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5154 - accuracy: 0.7991 - val_loss: 0.5505 - val_accuracy: 0.7580\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63b0340450>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(l=0.01), input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid',kernel_regularizer=regularizers.l1(l=0.01)))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAQij60B1gsy",
        "outputId": "e3f17a1c-85e8-4796-d2fd-9a6d39a1dae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,793,729\n",
            "Trainable params: 2,789,889\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "echtDfZQelrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "B_EQV_G62ycq",
        "outputId": "84074367-49bc-4b4f-e9c5-253e6ceb480a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 91s 206ms/step - loss: 84.0698 - accuracy: 0.5084 - val_loss: 20.5847 - val_accuracy: 0.5000\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 21.4713 - accuracy: 0.5098 - val_loss: 16.2612 - val_accuracy: 0.5000\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 15.9331 - accuracy: 0.5025 - val_loss: 14.5918 - val_accuracy: 0.5000\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 14.5921 - accuracy: 0.5000 - val_loss: 14.5923 - val_accuracy: 0.5000\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 14.5922 - accuracy: 0.4970 - val_loss: 14.5921 - val_accuracy: 0.5000\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 14.5923 - accuracy: 0.4956 - val_loss: 14.5924 - val_accuracy: 0.5000\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 14.5923 - accuracy: 0.4985 - val_loss: 14.5922 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 14.5924 - accuracy: 0.4918 - val_loss: 14.5925 - val_accuracy: 0.5000\n",
            "Epoch 9/80\n",
            "319/375 [========================>.....] - ETA: 10s - loss: 14.5924 - accuracy: 0.4908"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c9390c15dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(l=0.01),input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DISVWenH5kao",
        "outputId": "e0941955-9413-4d53-c3fe-55dc0fc40c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_26 (Conv2D)          (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 148, 148, 32)     128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 74, 74, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 72, 72, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 36, 36, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 34, 34, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 17, 17, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 15, 15, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 7, 7, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 5, 5, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 2, 2, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " batch_normalization_46 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_47 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_48 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_49 (Bat  (None, 32)               128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,793,729\n",
            "Trainable params: 2,789,889\n",
            "Non-trainable params: 3,840\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sgTFXsYA655t",
        "outputId": "115274eb-d3cc-42d6-c6b0-63a2f4865018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 79s 204ms/step - loss: 9.6605 - accuracy: 0.5521 - val_loss: 2.0295 - val_accuracy: 0.5005\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 1.2663 - accuracy: 0.6518 - val_loss: 1.3274 - val_accuracy: 0.5620\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.9213 - accuracy: 0.6973 - val_loss: 1.4038 - val_accuracy: 0.5005\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.8139 - accuracy: 0.7114 - val_loss: 0.8052 - val_accuracy: 0.6848\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.7711 - accuracy: 0.7181 - val_loss: 0.9159 - val_accuracy: 0.6055\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.7444 - accuracy: 0.7163 - val_loss: 1.0207 - val_accuracy: 0.5238\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.7277 - accuracy: 0.7197 - val_loss: 0.7010 - val_accuracy: 0.7377\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.7231 - accuracy: 0.7311 - val_loss: 0.6945 - val_accuracy: 0.7415\n",
            "Epoch 9/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.7061 - accuracy: 0.7328 - val_loss: 0.7189 - val_accuracy: 0.7390\n",
            "Epoch 10/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6970 - accuracy: 0.7406 - val_loss: 0.6749 - val_accuracy: 0.7530\n",
            "Epoch 11/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6800 - accuracy: 0.7504 - val_loss: 1.0480 - val_accuracy: 0.5587\n",
            "Epoch 12/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6733 - accuracy: 0.7527 - val_loss: 0.7157 - val_accuracy: 0.7070\n",
            "Epoch 13/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.6632 - accuracy: 0.7582 - val_loss: 0.7706 - val_accuracy: 0.6890\n",
            "Epoch 14/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.6526 - accuracy: 0.7629 - val_loss: 0.9626 - val_accuracy: 0.5970\n",
            "Epoch 15/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6428 - accuracy: 0.7702 - val_loss: 0.6340 - val_accuracy: 0.7527\n",
            "Epoch 16/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6295 - accuracy: 0.7694 - val_loss: 0.8103 - val_accuracy: 0.6467\n",
            "Epoch 17/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.6195 - accuracy: 0.7780 - val_loss: 0.6858 - val_accuracy: 0.7185\n",
            "Epoch 18/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6193 - accuracy: 0.7718 - val_loss: 0.7317 - val_accuracy: 0.6712\n",
            "Epoch 19/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6078 - accuracy: 0.7789 - val_loss: 0.6507 - val_accuracy: 0.7602\n",
            "Epoch 20/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6118 - accuracy: 0.7824 - val_loss: 0.6565 - val_accuracy: 0.7427\n",
            "Epoch 21/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.6045 - accuracy: 0.7776 - val_loss: 0.6473 - val_accuracy: 0.7427\n",
            "Epoch 22/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.6028 - accuracy: 0.7816 - val_loss: 0.6727 - val_accuracy: 0.7295\n",
            "Epoch 23/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.5998 - accuracy: 0.7826 - val_loss: 0.5807 - val_accuracy: 0.7843\n",
            "Epoch 24/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.5884 - accuracy: 0.7861 - val_loss: 0.6175 - val_accuracy: 0.7520\n",
            "Epoch 25/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5841 - accuracy: 0.7847 - val_loss: 0.6636 - val_accuracy: 0.7100\n",
            "Epoch 26/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5819 - accuracy: 0.7832 - val_loss: 0.5995 - val_accuracy: 0.7812\n",
            "Epoch 27/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5896 - accuracy: 0.7847 - val_loss: 0.6442 - val_accuracy: 0.7433\n",
            "Epoch 28/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5866 - accuracy: 0.7816 - val_loss: 0.6958 - val_accuracy: 0.6762\n",
            "Epoch 29/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.5788 - accuracy: 0.7857 - val_loss: 0.6548 - val_accuracy: 0.7473\n",
            "Epoch 30/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5668 - accuracy: 0.7935 - val_loss: 0.6380 - val_accuracy: 0.7575\n",
            "Epoch 31/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5741 - accuracy: 0.7858 - val_loss: 0.6129 - val_accuracy: 0.7487\n",
            "Epoch 32/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5673 - accuracy: 0.7972 - val_loss: 0.5931 - val_accuracy: 0.7628\n",
            "Epoch 33/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5637 - accuracy: 0.7897 - val_loss: 0.6058 - val_accuracy: 0.7502\n",
            "Epoch 34/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5650 - accuracy: 0.7837 - val_loss: 0.5770 - val_accuracy: 0.7705\n",
            "Epoch 35/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5605 - accuracy: 0.7903 - val_loss: 0.7444 - val_accuracy: 0.6225\n",
            "Epoch 36/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.5567 - accuracy: 0.7876 - val_loss: 0.5501 - val_accuracy: 0.7955\n",
            "Epoch 37/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5534 - accuracy: 0.7954 - val_loss: 0.6170 - val_accuracy: 0.7405\n",
            "Epoch 38/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5599 - accuracy: 0.7928 - val_loss: 0.5987 - val_accuracy: 0.7590\n",
            "Epoch 39/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5544 - accuracy: 0.7979 - val_loss: 0.6277 - val_accuracy: 0.7275\n",
            "Epoch 40/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5507 - accuracy: 0.7969 - val_loss: 0.6233 - val_accuracy: 0.7297\n",
            "Epoch 41/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5491 - accuracy: 0.7958 - val_loss: 0.5531 - val_accuracy: 0.7870\n",
            "Epoch 42/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.5411 - accuracy: 0.8038 - val_loss: 0.6651 - val_accuracy: 0.6765\n",
            "Epoch 43/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5414 - accuracy: 0.7990 - val_loss: 0.5509 - val_accuracy: 0.7897\n",
            "Epoch 44/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5449 - accuracy: 0.7987 - val_loss: 0.5983 - val_accuracy: 0.7650\n",
            "Epoch 45/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5420 - accuracy: 0.7984 - val_loss: 0.6023 - val_accuracy: 0.7648\n",
            "Epoch 46/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5397 - accuracy: 0.8008 - val_loss: 0.6263 - val_accuracy: 0.7372\n",
            "Epoch 47/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5359 - accuracy: 0.8030 - val_loss: 0.5514 - val_accuracy: 0.7893\n",
            "Epoch 48/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5339 - accuracy: 0.7972 - val_loss: 0.6113 - val_accuracy: 0.7155\n",
            "Epoch 49/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5340 - accuracy: 0.8018 - val_loss: 0.6292 - val_accuracy: 0.7147\n",
            "Epoch 50/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.5333 - accuracy: 0.7972 - val_loss: 0.5493 - val_accuracy: 0.7993\n",
            "Epoch 51/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5325 - accuracy: 0.7986 - val_loss: 0.5317 - val_accuracy: 0.8018\n",
            "Epoch 52/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5272 - accuracy: 0.8063 - val_loss: 0.5938 - val_accuracy: 0.7492\n",
            "Epoch 53/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5326 - accuracy: 0.8012 - val_loss: 0.8855 - val_accuracy: 0.6072\n",
            "Epoch 54/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5286 - accuracy: 0.8011 - val_loss: 0.5466 - val_accuracy: 0.7952\n",
            "Epoch 55/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5260 - accuracy: 0.8016 - val_loss: 0.5337 - val_accuracy: 0.8152\n",
            "Epoch 56/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5319 - accuracy: 0.8040 - val_loss: 0.5008 - val_accuracy: 0.8110\n",
            "Epoch 57/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5244 - accuracy: 0.8042 - val_loss: 0.5393 - val_accuracy: 0.8092\n",
            "Epoch 58/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5282 - accuracy: 0.8020 - val_loss: 0.5467 - val_accuracy: 0.7845\n",
            "Epoch 59/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5221 - accuracy: 0.8025 - val_loss: 0.6933 - val_accuracy: 0.7025\n",
            "Epoch 60/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5239 - accuracy: 0.7988 - val_loss: 0.4942 - val_accuracy: 0.8195\n",
            "Epoch 61/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5264 - accuracy: 0.8023 - val_loss: 0.5665 - val_accuracy: 0.7728\n",
            "Epoch 62/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5199 - accuracy: 0.8006 - val_loss: 0.5101 - val_accuracy: 0.8125\n",
            "Epoch 63/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5237 - accuracy: 0.8037 - val_loss: 0.6308 - val_accuracy: 0.7385\n",
            "Epoch 64/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.5185 - accuracy: 0.8062 - val_loss: 0.6117 - val_accuracy: 0.7473\n",
            "Epoch 65/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5185 - accuracy: 0.8035 - val_loss: 0.6185 - val_accuracy: 0.7340\n",
            "Epoch 66/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5257 - accuracy: 0.7969 - val_loss: 0.6696 - val_accuracy: 0.6758\n",
            "Epoch 67/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5184 - accuracy: 0.8069 - val_loss: 0.7002 - val_accuracy: 0.6083\n",
            "Epoch 68/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.5182 - accuracy: 0.8042 - val_loss: 0.5090 - val_accuracy: 0.8167\n",
            "Epoch 69/80\n",
            "312/375 [=======================>......] - ETA: 11s - loss: 0.5135 - accuracy: 0.8058"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c9390c15dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEgZe3AVLk2A",
        "outputId": "4528227e-0a31-4182-d729-b4561282b583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,839,617\n",
            "Trainable params: 1,837,313\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YnZZSXPlMGbn",
        "outputId": "0e6561a0-6693-4f1e-9125-c1c8b40e4e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 90s 202ms/step - loss: 0.7818 - accuracy: 0.6158 - val_loss: 0.7062 - val_accuracy: 0.6633\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.5338 - accuracy: 0.7379 - val_loss: 0.5702 - val_accuracy: 0.7322\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.4439 - accuracy: 0.7879 - val_loss: 0.4255 - val_accuracy: 0.7983\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.4104 - accuracy: 0.8056 - val_loss: 0.5353 - val_accuracy: 0.7663\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3739 - accuracy: 0.8327 - val_loss: 0.7379 - val_accuracy: 0.7092\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.3670 - accuracy: 0.8333 - val_loss: 0.4365 - val_accuracy: 0.8085\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.3470 - accuracy: 0.8414 - val_loss: 0.3670 - val_accuracy: 0.8400\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.3391 - accuracy: 0.8481 - val_loss: 0.4585 - val_accuracy: 0.7785\n",
            "Epoch 9/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.3229 - accuracy: 0.8530 - val_loss: 0.6096 - val_accuracy: 0.7220\n",
            "Epoch 10/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.3184 - accuracy: 0.8604 - val_loss: 0.3743 - val_accuracy: 0.8300\n",
            "Epoch 11/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3128 - accuracy: 0.8597 - val_loss: 0.6345 - val_accuracy: 0.7280\n",
            "Epoch 12/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2906 - accuracy: 0.8763 - val_loss: 0.3146 - val_accuracy: 0.8627\n",
            "Epoch 13/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2902 - accuracy: 0.8767 - val_loss: 0.3263 - val_accuracy: 0.8550\n",
            "Epoch 14/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2893 - accuracy: 0.8776 - val_loss: 0.2907 - val_accuracy: 0.8767\n",
            "Epoch 15/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2806 - accuracy: 0.8789 - val_loss: 0.3095 - val_accuracy: 0.8673\n",
            "Epoch 16/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2654 - accuracy: 0.8868 - val_loss: 0.3420 - val_accuracy: 0.8565\n",
            "Epoch 17/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2709 - accuracy: 0.8842 - val_loss: 0.3547 - val_accuracy: 0.8487\n",
            "Epoch 18/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2557 - accuracy: 0.8923 - val_loss: 0.3441 - val_accuracy: 0.8503\n",
            "Epoch 19/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2438 - accuracy: 0.8994 - val_loss: 0.3556 - val_accuracy: 0.8478\n",
            "Epoch 20/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2377 - accuracy: 0.9007 - val_loss: 0.4009 - val_accuracy: 0.8257\n",
            "Epoch 21/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2368 - accuracy: 0.8999 - val_loss: 0.3625 - val_accuracy: 0.8453\n",
            "Epoch 22/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2339 - accuracy: 0.9044 - val_loss: 0.2878 - val_accuracy: 0.8755\n",
            "Epoch 23/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2330 - accuracy: 0.9050 - val_loss: 0.3374 - val_accuracy: 0.8555\n",
            "Epoch 24/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2271 - accuracy: 0.9064 - val_loss: 0.2912 - val_accuracy: 0.8790\n",
            "Epoch 25/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2189 - accuracy: 0.9113 - val_loss: 0.3191 - val_accuracy: 0.8733\n",
            "Epoch 26/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2103 - accuracy: 0.9148 - val_loss: 0.3527 - val_accuracy: 0.8553\n",
            "Epoch 27/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2176 - accuracy: 0.9117 - val_loss: 0.3388 - val_accuracy: 0.8622\n",
            "Epoch 28/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2042 - accuracy: 0.9158 - val_loss: 0.4274 - val_accuracy: 0.8253\n",
            "Epoch 29/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.2039 - accuracy: 0.9182 - val_loss: 0.2916 - val_accuracy: 0.8817\n",
            "Epoch 30/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1957 - accuracy: 0.9224 - val_loss: 0.2822 - val_accuracy: 0.8848\n",
            "Epoch 31/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1959 - accuracy: 0.9237 - val_loss: 0.3040 - val_accuracy: 0.8810\n",
            "Epoch 32/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1895 - accuracy: 0.9231 - val_loss: 0.4249 - val_accuracy: 0.8292\n",
            "Epoch 33/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.1975 - accuracy: 0.9188 - val_loss: 0.3616 - val_accuracy: 0.8608\n",
            "Epoch 34/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1860 - accuracy: 0.9259 - val_loss: 0.3249 - val_accuracy: 0.8792\n",
            "Epoch 35/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1772 - accuracy: 0.9278 - val_loss: 0.3605 - val_accuracy: 0.8622\n",
            "Epoch 36/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1810 - accuracy: 0.9291 - val_loss: 0.3658 - val_accuracy: 0.8537\n",
            "Epoch 37/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1745 - accuracy: 0.9326 - val_loss: 0.3315 - val_accuracy: 0.8658\n",
            "Epoch 38/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1711 - accuracy: 0.9320 - val_loss: 0.4247 - val_accuracy: 0.8545\n",
            "Epoch 39/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1648 - accuracy: 0.9345 - val_loss: 0.3343 - val_accuracy: 0.8740\n",
            "Epoch 40/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1697 - accuracy: 0.9352 - val_loss: 0.3440 - val_accuracy: 0.8745\n",
            "Epoch 41/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1767 - accuracy: 0.9319 - val_loss: 0.3282 - val_accuracy: 0.8715\n",
            "Epoch 42/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.1587 - accuracy: 0.9404 - val_loss: 0.3620 - val_accuracy: 0.8648\n",
            "Epoch 43/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1589 - accuracy: 0.9391 - val_loss: 0.3355 - val_accuracy: 0.8685\n",
            "Epoch 44/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1600 - accuracy: 0.9366 - val_loss: 0.3275 - val_accuracy: 0.8785\n",
            "Epoch 45/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1502 - accuracy: 0.9433 - val_loss: 0.3323 - val_accuracy: 0.8808\n",
            "Epoch 46/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.1531 - accuracy: 0.9407 - val_loss: 0.3442 - val_accuracy: 0.8735\n",
            "Epoch 47/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1472 - accuracy: 0.9416 - val_loss: 0.3392 - val_accuracy: 0.8733\n",
            "Epoch 48/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.1364 - accuracy: 0.9467 - val_loss: 0.3848 - val_accuracy: 0.8665\n",
            "Epoch 49/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1471 - accuracy: 0.9441 - val_loss: 0.3634 - val_accuracy: 0.8763\n",
            "Epoch 50/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1479 - accuracy: 0.9457 - val_loss: 0.3752 - val_accuracy: 0.8698\n",
            "Epoch 51/80\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.1416 - accuracy: 0.9470 - val_loss: 0.3228 - val_accuracy: 0.8882\n",
            "Epoch 52/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.1408 - accuracy: 0.9469 - val_loss: 0.4659 - val_accuracy: 0.8345\n",
            "Epoch 53/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1459 - accuracy: 0.9449 - val_loss: 0.3542 - val_accuracy: 0.8763\n",
            "Epoch 54/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.1343 - accuracy: 0.9517 - val_loss: 0.3586 - val_accuracy: 0.8775\n",
            "Epoch 55/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1363 - accuracy: 0.9534 - val_loss: 0.3350 - val_accuracy: 0.8792\n",
            "Epoch 56/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1299 - accuracy: 0.9508 - val_loss: 0.3168 - val_accuracy: 0.8953\n",
            "Epoch 57/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1397 - accuracy: 0.9478 - val_loss: 0.3104 - val_accuracy: 0.8963\n",
            "Epoch 58/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1329 - accuracy: 0.9501 - val_loss: 0.3516 - val_accuracy: 0.8715\n",
            "Epoch 59/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1345 - accuracy: 0.9504 - val_loss: 0.3424 - val_accuracy: 0.8742\n",
            "Epoch 60/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1347 - accuracy: 0.9479 - val_loss: 0.3451 - val_accuracy: 0.8745\n",
            "Epoch 61/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1230 - accuracy: 0.9545 - val_loss: 0.3374 - val_accuracy: 0.8830\n",
            "Epoch 62/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1209 - accuracy: 0.9563 - val_loss: 0.3749 - val_accuracy: 0.8730\n",
            "Epoch 63/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1288 - accuracy: 0.9528 - val_loss: 0.3311 - val_accuracy: 0.8823\n",
            "Epoch 64/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1207 - accuracy: 0.9565 - val_loss: 0.4929 - val_accuracy: 0.8413\n",
            "Epoch 65/80\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.1169 - accuracy: 0.9564 - val_loss: 0.4028 - val_accuracy: 0.8705\n",
            "Epoch 66/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.1167 - accuracy: 0.9552 - val_loss: 0.3442 - val_accuracy: 0.8857\n",
            "Epoch 67/80\n",
            " 45/375 [==>...........................] - ETA: 1:02 - loss: 0.1331 - accuracy: 0.9569"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c9390c15dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQnSMog7A9_b",
        "outputId": "d01588b8-fbbe-4deb-f870-efb80ef5758a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 148, 148, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 82944)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2654240   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,674,177\n",
            "Trainable params: 2,673,921\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cdRaO2RZBPAR",
        "outputId": "50335b24-a6d3-4ed1-8872-d3057355b45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 83s 213ms/step - loss: 0.6868 - accuracy: 0.6217 - val_loss: 78.1785 - val_accuracy: 0.5000\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 79s 210ms/step - loss: 0.5876 - accuracy: 0.7041 - val_loss: 8.4821 - val_accuracy: 0.5182\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.5540 - accuracy: 0.7192 - val_loss: 10.8900 - val_accuracy: 0.6108\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.5300 - accuracy: 0.7401 - val_loss: 13.4160 - val_accuracy: 0.6102\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.5172 - accuracy: 0.7462 - val_loss: 3.3276 - val_accuracy: 0.7067\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 78s 207ms/step - loss: 0.4893 - accuracy: 0.7642 - val_loss: 5.3213 - val_accuracy: 0.6900\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.4697 - accuracy: 0.7781 - val_loss: 0.6084 - val_accuracy: 0.7510\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.4577 - accuracy: 0.7851 - val_loss: 0.9215 - val_accuracy: 0.6283\n",
            "Epoch 9/80\n",
            "375/375 [==============================] - 78s 208ms/step - loss: 0.4422 - accuracy: 0.7961 - val_loss: 0.6050 - val_accuracy: 0.6967\n",
            "Epoch 10/80\n",
            "375/375 [==============================] - 79s 211ms/step - loss: 0.4319 - accuracy: 0.8012 - val_loss: 1.4196 - val_accuracy: 0.6745\n",
            "Epoch 11/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.4214 - accuracy: 0.8087 - val_loss: 0.7052 - val_accuracy: 0.6923\n",
            "Epoch 12/80\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.4108 - accuracy: 0.8108 - val_loss: 0.6243 - val_accuracy: 0.6528\n",
            "Epoch 13/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.4133 - accuracy: 0.8108 - val_loss: 0.6202 - val_accuracy: 0.5770\n",
            "Epoch 14/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.4032 - accuracy: 0.8169 - val_loss: 0.6043 - val_accuracy: 0.6628\n",
            "Epoch 15/80\n",
            "375/375 [==============================] - 74s 199ms/step - loss: 0.3903 - accuracy: 0.8238 - val_loss: 0.6009 - val_accuracy: 0.6285\n",
            "Epoch 16/80\n",
            "375/375 [==============================] - 74s 197ms/step - loss: 0.3765 - accuracy: 0.8309 - val_loss: 0.6623 - val_accuracy: 0.5623\n",
            "Epoch 17/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3826 - accuracy: 0.8278 - val_loss: 0.6534 - val_accuracy: 0.5825\n",
            "Epoch 18/80\n",
            "221/375 [================>.............] - ETA: 28s - loss: 0.3883 - accuracy: 0.8225"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c9390c15dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A1WlqdsG1Oa",
        "outputId": "7730a290-67e9-4ab0-992d-670df449a78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 148, 148, 32)     128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 36992)             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1183776   \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,278,081\n",
            "Trainable params: 1,277,569\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=80,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "okHO8FadG8ZK",
        "outputId": "87936346-e3a8-44a5-f63b-93bf0dd409db"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "375/375 [==============================] - 79s 208ms/step - loss: 0.7079 - accuracy: 0.6397 - val_loss: 0.9897 - val_accuracy: 0.6255\n",
            "Epoch 2/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.5806 - accuracy: 0.7057 - val_loss: 0.5759 - val_accuracy: 0.7165\n",
            "Epoch 3/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.5250 - accuracy: 0.7409 - val_loss: 0.7091 - val_accuracy: 0.7293\n",
            "Epoch 4/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4791 - accuracy: 0.7720 - val_loss: 0.8391 - val_accuracy: 0.7100\n",
            "Epoch 5/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4500 - accuracy: 0.7885 - val_loss: 0.9211 - val_accuracy: 0.7325\n",
            "Epoch 6/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.4335 - accuracy: 0.7920 - val_loss: 0.6856 - val_accuracy: 0.7730\n",
            "Epoch 7/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.4130 - accuracy: 0.8061 - val_loss: 0.9702 - val_accuracy: 0.7232\n",
            "Epoch 8/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3984 - accuracy: 0.8163 - val_loss: 0.6136 - val_accuracy: 0.7990\n",
            "Epoch 9/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3837 - accuracy: 0.8237 - val_loss: 0.8782 - val_accuracy: 0.7322\n",
            "Epoch 10/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3799 - accuracy: 0.8260 - val_loss: 0.6430 - val_accuracy: 0.7887\n",
            "Epoch 11/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3709 - accuracy: 0.8297 - val_loss: 0.5385 - val_accuracy: 0.8100\n",
            "Epoch 12/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3604 - accuracy: 0.8372 - val_loss: 0.5633 - val_accuracy: 0.7993\n",
            "Epoch 13/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3623 - accuracy: 0.8337 - val_loss: 0.8017 - val_accuracy: 0.7563\n",
            "Epoch 14/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3605 - accuracy: 0.8341 - val_loss: 1.0435 - val_accuracy: 0.7085\n",
            "Epoch 15/80\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.3480 - accuracy: 0.8420 - val_loss: 0.7246 - val_accuracy: 0.7605\n",
            "Epoch 16/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3454 - accuracy: 0.8426 - val_loss: 0.5692 - val_accuracy: 0.7845\n",
            "Epoch 17/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3424 - accuracy: 0.8472 - val_loss: 0.3600 - val_accuracy: 0.8372\n",
            "Epoch 18/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3405 - accuracy: 0.8487 - val_loss: 0.5281 - val_accuracy: 0.7797\n",
            "Epoch 19/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3323 - accuracy: 0.8512 - val_loss: 0.7181 - val_accuracy: 0.7678\n",
            "Epoch 20/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3348 - accuracy: 0.8535 - val_loss: 0.5072 - val_accuracy: 0.8138\n",
            "Epoch 21/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3274 - accuracy: 0.8531 - val_loss: 0.8440 - val_accuracy: 0.7155\n",
            "Epoch 22/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3318 - accuracy: 0.8562 - val_loss: 0.4086 - val_accuracy: 0.8102\n",
            "Epoch 23/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3286 - accuracy: 0.8600 - val_loss: 0.5474 - val_accuracy: 0.7720\n",
            "Epoch 24/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3186 - accuracy: 0.8590 - val_loss: 0.4897 - val_accuracy: 0.8048\n",
            "Epoch 25/80\n",
            "375/375 [==============================] - 74s 198ms/step - loss: 0.3166 - accuracy: 0.8607 - val_loss: 0.8512 - val_accuracy: 0.7602\n",
            "Epoch 26/80\n",
            "375/375 [==============================] - 74s 196ms/step - loss: 0.3153 - accuracy: 0.8608 - val_loss: 0.8878 - val_accuracy: 0.7270\n",
            "Epoch 27/80\n",
            "375/375 [==============================] - 74s 196ms/step - loss: 0.3184 - accuracy: 0.8582 - val_loss: 0.4692 - val_accuracy: 0.7987\n",
            "Epoch 28/80\n",
            "375/375 [==============================] - 75s 199ms/step - loss: 0.3042 - accuracy: 0.8656 - val_loss: 0.3167 - val_accuracy: 0.8553\n",
            "Epoch 29/80\n",
            "375/375 [==============================] - 77s 206ms/step - loss: 0.3160 - accuracy: 0.8564 - val_loss: 0.3831 - val_accuracy: 0.8273\n",
            "Epoch 30/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.3105 - accuracy: 0.8646 - val_loss: 0.3537 - val_accuracy: 0.8422\n",
            "Epoch 31/80\n",
            "375/375 [==============================] - 76s 204ms/step - loss: 0.3096 - accuracy: 0.8674 - val_loss: 0.4899 - val_accuracy: 0.8108\n",
            "Epoch 32/80\n",
            "375/375 [==============================] - 77s 205ms/step - loss: 0.3106 - accuracy: 0.8659 - val_loss: 0.3665 - val_accuracy: 0.8405\n",
            "Epoch 33/80\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.3038 - accuracy: 0.8658 - val_loss: 0.3375 - val_accuracy: 0.8493\n",
            "Epoch 34/80\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.3000 - accuracy: 0.8703 - val_loss: 0.6629 - val_accuracy: 0.7595\n",
            "Epoch 35/80\n",
            "373/375 [============================>.] - ETA: 0s - loss: 0.3048 - accuracy: 0.8709"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-c9390c15dbd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow"
      ],
      "metadata": {
        "id": "8lBeWXs3R7Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tensorflow.keras.optimizers.RMSprop(learning_rate=0.01)\n"
      ],
      "metadata": {
        "id": "SLaB3932jCm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='swish', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='swish', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='swish',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='swish',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='swish',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='swish'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='swish'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WtIbZ6oRI2X",
        "outputId": "5fda3837-feb2-4788-a3ac-761c252e3dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,839,617\n",
            "Trainable params: 1,837,313\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rIvneAqfREbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gBGnxmOWSNaT",
        "outputId": "4344d1a7-5e39-461f-b56c-20f68997f5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "300/300 [==============================] - 82s 223ms/step - loss: 0.6582 - accuracy: 0.6241 - val_loss: 0.7795 - val_accuracy: 0.6531\n",
            "Epoch 2/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.5401 - accuracy: 0.7295 - val_loss: 0.6077 - val_accuracy: 0.7027\n",
            "Epoch 3/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.4827 - accuracy: 0.7678 - val_loss: 0.5204 - val_accuracy: 0.7359\n",
            "Epoch 4/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.4546 - accuracy: 0.7887 - val_loss: 0.4203 - val_accuracy: 0.8072\n",
            "Epoch 5/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.4362 - accuracy: 0.7972 - val_loss: 0.6532 - val_accuracy: 0.6777\n",
            "Epoch 6/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.4206 - accuracy: 0.8061 - val_loss: 0.4866 - val_accuracy: 0.7763\n",
            "Epoch 7/100\n",
            "300/300 [==============================] - 66s 218ms/step - loss: 0.4142 - accuracy: 0.8072 - val_loss: 0.4931 - val_accuracy: 0.7652\n",
            "Epoch 8/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.4043 - accuracy: 0.8115 - val_loss: 0.4376 - val_accuracy: 0.8025\n",
            "Epoch 9/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.3942 - accuracy: 0.8238 - val_loss: 0.3981 - val_accuracy: 0.8202\n",
            "Epoch 10/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.3899 - accuracy: 0.8233 - val_loss: 0.4210 - val_accuracy: 0.8178\n",
            "Epoch 11/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.3846 - accuracy: 0.8244 - val_loss: 0.4872 - val_accuracy: 0.7412\n",
            "Epoch 12/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.3851 - accuracy: 0.8268 - val_loss: 0.3569 - val_accuracy: 0.8411\n",
            "Epoch 13/100\n",
            "300/300 [==============================] - 66s 222ms/step - loss: 0.3689 - accuracy: 0.8293 - val_loss: 0.4494 - val_accuracy: 0.8183\n",
            "Epoch 14/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.3647 - accuracy: 0.8371 - val_loss: 0.4044 - val_accuracy: 0.8120\n",
            "Epoch 15/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.3595 - accuracy: 0.8370 - val_loss: 0.3518 - val_accuracy: 0.8483\n",
            "Epoch 16/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.3538 - accuracy: 0.8449 - val_loss: 0.3916 - val_accuracy: 0.8172\n",
            "Epoch 17/100\n",
            "300/300 [==============================] - 67s 224ms/step - loss: 0.3490 - accuracy: 0.8424 - val_loss: 0.3726 - val_accuracy: 0.8333\n",
            "Epoch 18/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.3516 - accuracy: 0.8410 - val_loss: 0.3737 - val_accuracy: 0.8261\n",
            "Epoch 19/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.3413 - accuracy: 0.8507 - val_loss: 0.6415 - val_accuracy: 0.6856\n",
            "Epoch 20/100\n",
            "300/300 [==============================] - 66s 222ms/step - loss: 0.3395 - accuracy: 0.8519 - val_loss: 0.3496 - val_accuracy: 0.8438\n",
            "Epoch 21/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.3377 - accuracy: 0.8467 - val_loss: 0.3546 - val_accuracy: 0.8389\n",
            "Epoch 22/100\n",
            "300/300 [==============================] - 66s 221ms/step - loss: 0.3368 - accuracy: 0.8508 - val_loss: 0.4653 - val_accuracy: 0.7927\n",
            "Epoch 23/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.3262 - accuracy: 0.8503 - val_loss: 0.7772 - val_accuracy: 0.7123\n",
            "Epoch 24/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.3226 - accuracy: 0.8565 - val_loss: 0.4075 - val_accuracy: 0.8333\n",
            "Epoch 25/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.3315 - accuracy: 0.8505 - val_loss: 0.3404 - val_accuracy: 0.8487\n",
            "Epoch 26/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.3248 - accuracy: 0.8551 - val_loss: 0.3396 - val_accuracy: 0.8462\n",
            "Epoch 27/100\n",
            "300/300 [==============================] - 66s 221ms/step - loss: 0.3136 - accuracy: 0.8640 - val_loss: 0.9688 - val_accuracy: 0.6739\n",
            "Epoch 28/100\n",
            "300/300 [==============================] - 67s 224ms/step - loss: 0.3104 - accuracy: 0.8602 - val_loss: 0.3741 - val_accuracy: 0.8227\n",
            "Epoch 29/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.3111 - accuracy: 0.8662 - val_loss: 0.3708 - val_accuracy: 0.8331\n",
            "Epoch 30/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.3097 - accuracy: 0.8625 - val_loss: 0.3690 - val_accuracy: 0.8345\n",
            "Epoch 31/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.3080 - accuracy: 0.8640 - val_loss: 0.3439 - val_accuracy: 0.8498\n",
            "Epoch 32/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.3085 - accuracy: 0.8637 - val_loss: 0.4899 - val_accuracy: 0.8033\n",
            "Epoch 33/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.3010 - accuracy: 0.8674 - val_loss: 0.4558 - val_accuracy: 0.8008\n",
            "Epoch 34/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.3090 - accuracy: 0.8655 - val_loss: 0.3168 - val_accuracy: 0.8592\n",
            "Epoch 35/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2989 - accuracy: 0.8680 - val_loss: 0.3644 - val_accuracy: 0.8427\n",
            "Epoch 36/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2917 - accuracy: 0.8728 - val_loss: 0.3698 - val_accuracy: 0.8464\n",
            "Epoch 37/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2874 - accuracy: 0.8796 - val_loss: 0.4033 - val_accuracy: 0.8242\n",
            "Epoch 38/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2918 - accuracy: 0.8743 - val_loss: 0.3372 - val_accuracy: 0.8514\n",
            "Epoch 39/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2873 - accuracy: 0.8741 - val_loss: 0.3764 - val_accuracy: 0.8261\n",
            "Epoch 40/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2765 - accuracy: 0.8800 - val_loss: 0.3470 - val_accuracy: 0.8531\n",
            "Epoch 41/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2864 - accuracy: 0.8761 - val_loss: 0.3248 - val_accuracy: 0.8547\n",
            "Epoch 42/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2788 - accuracy: 0.8771 - val_loss: 0.4077 - val_accuracy: 0.8225\n",
            "Epoch 43/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2872 - accuracy: 0.8743 - val_loss: 0.4051 - val_accuracy: 0.8164\n",
            "Epoch 44/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2809 - accuracy: 0.8806 - val_loss: 0.4692 - val_accuracy: 0.7880\n",
            "Epoch 45/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2734 - accuracy: 0.8841 - val_loss: 1.3675 - val_accuracy: 0.6392\n",
            "Epoch 46/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2858 - accuracy: 0.8742 - val_loss: 0.3730 - val_accuracy: 0.8383\n",
            "Epoch 47/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2673 - accuracy: 0.8851 - val_loss: 0.3974 - val_accuracy: 0.8370\n",
            "Epoch 48/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2629 - accuracy: 0.8891 - val_loss: 0.3207 - val_accuracy: 0.8555\n",
            "Epoch 49/100\n",
            "300/300 [==============================] - 66s 222ms/step - loss: 0.2657 - accuracy: 0.8891 - val_loss: 0.4934 - val_accuracy: 0.7967\n",
            "Epoch 50/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2637 - accuracy: 0.8896 - val_loss: 0.3612 - val_accuracy: 0.8512\n",
            "Epoch 51/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2730 - accuracy: 0.8867 - val_loss: 0.3298 - val_accuracy: 0.8591\n",
            "Epoch 52/100\n",
            "300/300 [==============================] - 66s 222ms/step - loss: 0.2602 - accuracy: 0.8928 - val_loss: 0.4063 - val_accuracy: 0.8314\n",
            "Epoch 53/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2647 - accuracy: 0.8874 - val_loss: 0.3650 - val_accuracy: 0.8381\n",
            "Epoch 54/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2521 - accuracy: 0.8955 - val_loss: 0.3424 - val_accuracy: 0.8439\n",
            "Epoch 55/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2594 - accuracy: 0.8875 - val_loss: 0.3439 - val_accuracy: 0.8545\n",
            "Epoch 56/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2536 - accuracy: 0.8921 - val_loss: 0.3558 - val_accuracy: 0.8517\n",
            "Epoch 57/100\n",
            "300/300 [==============================] - 65s 216ms/step - loss: 0.2526 - accuracy: 0.8966 - val_loss: 0.3075 - val_accuracy: 0.8673\n",
            "Epoch 58/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2484 - accuracy: 0.8949 - val_loss: 0.3587 - val_accuracy: 0.8430\n",
            "Epoch 59/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2485 - accuracy: 0.8977 - val_loss: 0.3802 - val_accuracy: 0.8448\n",
            "Epoch 60/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2482 - accuracy: 0.8968 - val_loss: 0.3451 - val_accuracy: 0.8400\n",
            "Epoch 61/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2523 - accuracy: 0.8964 - val_loss: 0.4285 - val_accuracy: 0.8242\n",
            "Epoch 62/100\n",
            "300/300 [==============================] - 66s 221ms/step - loss: 0.2498 - accuracy: 0.8994 - val_loss: 0.3446 - val_accuracy: 0.8500\n",
            "Epoch 63/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2414 - accuracy: 0.8988 - val_loss: 0.5011 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.2392 - accuracy: 0.9009 - val_loss: 0.3530 - val_accuracy: 0.8477\n",
            "Epoch 65/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.2374 - accuracy: 0.9059 - val_loss: 0.3241 - val_accuracy: 0.8612\n",
            "Epoch 66/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2424 - accuracy: 0.9009 - val_loss: 0.3162 - val_accuracy: 0.8605\n",
            "Epoch 67/100\n",
            "300/300 [==============================] - 66s 221ms/step - loss: 0.2477 - accuracy: 0.8973 - val_loss: 0.4849 - val_accuracy: 0.7958\n",
            "Epoch 68/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2366 - accuracy: 0.9028 - val_loss: 0.4063 - val_accuracy: 0.8228\n",
            "Epoch 69/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2518 - accuracy: 0.8964 - val_loss: 0.3610 - val_accuracy: 0.8520\n",
            "Epoch 70/100\n",
            "300/300 [==============================] - 66s 218ms/step - loss: 0.2446 - accuracy: 0.8968 - val_loss: 0.3106 - val_accuracy: 0.8641\n",
            "Epoch 71/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2369 - accuracy: 0.9021 - val_loss: 0.3385 - val_accuracy: 0.8600\n",
            "Epoch 72/100\n",
            "300/300 [==============================] - 66s 218ms/step - loss: 0.2338 - accuracy: 0.9015 - val_loss: 0.3496 - val_accuracy: 0.8527\n",
            "Epoch 73/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2398 - accuracy: 0.8989 - val_loss: 0.5617 - val_accuracy: 0.7969\n",
            "Epoch 74/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2419 - accuracy: 0.8994 - val_loss: 0.3889 - val_accuracy: 0.8509\n",
            "Epoch 75/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2371 - accuracy: 0.9030 - val_loss: 0.4788 - val_accuracy: 0.8044\n",
            "Epoch 76/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2318 - accuracy: 0.9033 - val_loss: 0.4978 - val_accuracy: 0.8189\n",
            "Epoch 77/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2241 - accuracy: 0.9080 - val_loss: 0.3276 - val_accuracy: 0.8592\n",
            "Epoch 78/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2249 - accuracy: 0.9042 - val_loss: 0.3707 - val_accuracy: 0.8548\n",
            "Epoch 79/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2311 - accuracy: 0.9065 - val_loss: 0.3454 - val_accuracy: 0.8519\n",
            "Epoch 80/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2236 - accuracy: 0.9072 - val_loss: 0.3688 - val_accuracy: 0.8548\n",
            "Epoch 81/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2310 - accuracy: 0.9060 - val_loss: 0.3866 - val_accuracy: 0.8452\n",
            "Epoch 82/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2157 - accuracy: 0.9099 - val_loss: 0.3272 - val_accuracy: 0.8609\n",
            "Epoch 83/100\n",
            "300/300 [==============================] - 66s 218ms/step - loss: 0.2338 - accuracy: 0.9000 - val_loss: 0.3676 - val_accuracy: 0.8331\n",
            "Epoch 84/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2166 - accuracy: 0.9097 - val_loss: 0.4369 - val_accuracy: 0.8216\n",
            "Epoch 85/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2301 - accuracy: 0.9070 - val_loss: 0.3735 - val_accuracy: 0.8556\n",
            "Epoch 86/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2180 - accuracy: 0.9092 - val_loss: 0.3180 - val_accuracy: 0.8630\n",
            "Epoch 87/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2162 - accuracy: 0.9101 - val_loss: 0.3822 - val_accuracy: 0.8452\n",
            "Epoch 88/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2111 - accuracy: 0.9123 - val_loss: 0.5429 - val_accuracy: 0.8178\n",
            "Epoch 89/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2160 - accuracy: 0.9120 - val_loss: 0.3645 - val_accuracy: 0.8416\n",
            "Epoch 90/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2088 - accuracy: 0.9162 - val_loss: 0.3230 - val_accuracy: 0.8631\n",
            "Epoch 91/100\n",
            "300/300 [==============================] - 66s 220ms/step - loss: 0.2107 - accuracy: 0.9150 - val_loss: 0.3776 - val_accuracy: 0.8473\n",
            "Epoch 92/100\n",
            "300/300 [==============================] - 67s 223ms/step - loss: 0.2166 - accuracy: 0.9126 - val_loss: 0.3547 - val_accuracy: 0.8525\n",
            "Epoch 93/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2166 - accuracy: 0.9131 - val_loss: 0.3730 - val_accuracy: 0.8378\n",
            "Epoch 94/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2165 - accuracy: 0.9116 - val_loss: 0.3906 - val_accuracy: 0.8395\n",
            "Epoch 95/100\n",
            "300/300 [==============================] - 66s 218ms/step - loss: 0.2086 - accuracy: 0.9154 - val_loss: 0.4080 - val_accuracy: 0.8375\n",
            "Epoch 96/100\n",
            "300/300 [==============================] - 67s 222ms/step - loss: 0.2114 - accuracy: 0.9154 - val_loss: 0.3514 - val_accuracy: 0.8630\n",
            "Epoch 97/100\n",
            "300/300 [==============================] - 66s 219ms/step - loss: 0.2083 - accuracy: 0.9165 - val_loss: 0.3456 - val_accuracy: 0.8555\n",
            "Epoch 98/100\n",
            "300/300 [==============================] - 65s 217ms/step - loss: 0.2045 - accuracy: 0.9192 - val_loss: 0.3976 - val_accuracy: 0.8548\n",
            "Epoch 99/100\n",
            "300/300 [==============================] - 65s 218ms/step - loss: 0.2107 - accuracy: 0.9166 - val_loss: 0.3108 - val_accuracy: 0.8661\n",
            "Epoch 100/100\n",
            "140/300 [=============>................] - ETA: 30s - loss: 0.1977 - accuracy: 0.9225"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-46c1141b1907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     validation_data=validation_generator)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save_weights('model2_0.01_100.h5')"
      ],
      "metadata": {
        "id": "XXpo5FDIY5Y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model2_0.01_100.json','w') as f:\n",
        "    f.write(model.to_json())"
      ],
      "metadata": {
        "id": "4YrDTUBT-qJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OznF1sgpN5FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OQdvQe54N5Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=tensorflow.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
        "\n",
        "# make an object of sequential class\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal',input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\"\"\"model.add(Conv2D(512, (3, 3), activation='relu',kernel_regularizer=regularizers.l2(l=0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\"\"\"\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "txPdbx7yk9ND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9602407-23c2-4d52-cff1-ea5d548cc621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,839,617\n",
            "Trainable params: 1,837,313\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "hbgSZaF0lCQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bd38b20-4652-4bdc-d0c4-82c460152a58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2879 - accuracy: 0.8775 - val_loss: 0.4040 - val_accuracy: 0.8335\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.2911 - accuracy: 0.8784 - val_loss: 0.4110 - val_accuracy: 0.8345\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.2794 - accuracy: 0.8817 - val_loss: 0.5008 - val_accuracy: 0.8023\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 75s 201ms/step - loss: 0.2878 - accuracy: 0.8791 - val_loss: 0.4535 - val_accuracy: 0.8155\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.2797 - accuracy: 0.8796 - val_loss: 0.5449 - val_accuracy: 0.7937\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2751 - accuracy: 0.8817 - val_loss: 0.3917 - val_accuracy: 0.8335\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2725 - accuracy: 0.8859 - val_loss: 0.4084 - val_accuracy: 0.8332\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.2738 - accuracy: 0.8882 - val_loss: 0.3946 - val_accuracy: 0.8342\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.2708 - accuracy: 0.8846 - val_loss: 0.4858 - val_accuracy: 0.8135\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 76s 203ms/step - loss: 0.2667 - accuracy: 0.8901 - val_loss: 0.4532 - val_accuracy: 0.8257\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2688 - accuracy: 0.8848 - val_loss: 0.3834 - val_accuracy: 0.8418\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2649 - accuracy: 0.8882 - val_loss: 0.4368 - val_accuracy: 0.8310\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 75s 200ms/step - loss: 0.2461 - accuracy: 0.8965 - val_loss: 0.4500 - val_accuracy: 0.8250\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 76s 202ms/step - loss: 0.2591 - accuracy: 0.8932 - val_loss: 0.5230 - val_accuracy: 0.8117\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 76s 201ms/step - loss: 0.2586 - accuracy: 0.8903 - val_loss: 0.5216 - val_accuracy: 0.8105\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 77s 204ms/step - loss: 0.2540 - accuracy: 0.8918 - val_loss: 0.4590 - val_accuracy: 0.8195\n",
            "Epoch 17/100\n",
            " 67/375 [====>.........................] - ETA: 57s - loss: 0.2382 - accuracy: 0.9025"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# Model reconstruction from JSON file\n",
        "with open('/content/model_0.01_121.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "\n",
        "# Load weights into the new model\n",
        "model.load_weights('/content/model_0.01_121.h5')"
      ],
      "metadata": {
        "id": "BUvCGI7S9qRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZqMOF6vQ5OS",
        "outputId": "b6d4708d-1e3c-4da2-c5e4-3710823ae5a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 74, 74, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 36, 36, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17, 17, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 5, 5, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,839,617\n",
            "Trainable params: 1,837,313\n",
            "Non-trainable params: 2,304\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "cQntk5IFn1PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Model reconstruction from JSON file\n",
        "with open('/content/model_0.01_121.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "\n",
        "# Load weights into the new model\n",
        "model.load_weights('/content/model_0.01_121.h5')\n"
      ],
      "metadata": {
        "id": "ybjaG0NEn6Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "test_image=image.load_img('/content/bur.jpg',target_size=(img_width,img_height))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "test_image=test_image/255\n",
        "result=model.predict(test_image)\n",
        "#print(result[0][0])\n",
        "#train_generator.class_indices\n",
        "if result[0][0]<=0.5:\n",
        "    prediction='burger'\n",
        "else:\n",
        "    prediction='vadapaav'\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBz3Wry-uNn",
        "outputId": "416d5a12-74c2-46d8-e6be-8efe59ee6d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "burger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1XdEwpqCR8s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}